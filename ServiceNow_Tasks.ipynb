{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3d9292aae5324a42a6390b22ddbd9671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04f9043f5a73428fb8f9ab73156b54dd",
              "IPY_MODEL_c9e162486e794259a42a75a4ceaf8c59",
              "IPY_MODEL_055a8bf73e044a4b892013aa1544ae5e"
            ],
            "layout": "IPY_MODEL_4b230d64e9ec485d8be30cac6ef8b3ff"
          }
        },
        "04f9043f5a73428fb8f9ab73156b54dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_761d5d89812c4aaea92dc2a68f872c10",
            "placeholder": "​",
            "style": "IPY_MODEL_4ca0a35edd3f434ca4ff2bcfb551daf2",
            "value": "Map: 100%"
          }
        },
        "c9e162486e794259a42a75a4ceaf8c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab5c436670bc462e828fcbad19fb0769",
            "max": 87599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a23973a6eb6141c49626931c8ced16b5",
            "value": 87599
          }
        },
        "055a8bf73e044a4b892013aa1544ae5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d6805ed26074739bf9640c5d1886719",
            "placeholder": "​",
            "style": "IPY_MODEL_2103c917c61a4283bb31fe48bf113008",
            "value": " 87599/87599 [00:10&lt;00:00, 8902.69 examples/s]"
          }
        },
        "4b230d64e9ec485d8be30cac6ef8b3ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "761d5d89812c4aaea92dc2a68f872c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ca0a35edd3f434ca4ff2bcfb551daf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab5c436670bc462e828fcbad19fb0769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a23973a6eb6141c49626931c8ced16b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d6805ed26074739bf9640c5d1886719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2103c917c61a4283bb31fe48bf113008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4I2sQrWD0He",
        "outputId": "d2fe1ad7-fcaa-41c0-eca2-a21ae39c5849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.17.1 dill-0.3.8 multiprocess-0.70.16\n"
          ]
        }
      ],
      "source": [
        "# @title Requirements\n",
        "\n",
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Libraries\n",
        "\n",
        "from tqdm import tqdm\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
        "import torch\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset, load_metric"
      ],
      "metadata": {
        "id": "4aQ52r47EB7J"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g5Lhr25ZGJdE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task 1: Use a pre-trained google/flan-t5-small as the model:\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InQRAGhIEdBs",
        "outputId": "278b768d-db22-4508-d116-74f2eaa8f9fb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58daXI2GGInz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task 2: Verify if the summarization task works:\n",
        "\n",
        "\n",
        "input_text = \"\"\"World War I[j] or the First World War (28 July 1914 – 11 November 1918) was a global conflict fought between two coalitions: the Allies and the Central Powers. Battles took place throughout Europe, the Middle East, Africa, the Pacific, and parts of Asia. One of the deadliest wars in history, it ultimately resulted in an estimated 9 million soldiers dead and 23 million wounded, plus another 5 million civilian deaths from numerous causes. Millions more died as a result of genocide, and the war was a major factor in the 1918 Spanish flu pandemic.\"\"\"\n",
        "\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "summary_ids = model.generate(input_ids, max_length=100, num_beams=4)\n",
        "\n",
        "summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(\"Generated Summary:\", summary_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL1_KpiiExgg",
        "outputId": "554330b2-55dd-45c0-c5d2-8a543941044c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary: World War I[j] or the First World War (28 July 1914 – 11 November 1918) was a global conflict fought between two coalitions: the Allies and the Central Powers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X5s0uLygGH-M"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task 3: Verify if the Q&A task works:\n",
        "\n",
        "\n",
        "context = \"Albert Einstein was a German-born theoretical physicist who developed the theory of relativity.\"\n",
        "question = \"Who was Albert Einstein?\"\n",
        "\n",
        "input_text = f\"question: {question} context: {context}\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "output = model.generate(input_ids)\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(\" \")\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h_B3ya7Fbx9",
        "outputId": "d82c3b50-e336-40bd-8037-c65ea02da321"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "physicist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MrZPeKU4GK7M"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task 4: Verify if English to French translation task works:\n",
        "\n",
        "english_text = \"Hello, how are you?\"\n",
        "\n",
        "input_ids = tokenizer.encode(\"translate English to French: \" + english_text, return_tensors=\"pt\")\n",
        "output_ids = model.generate(input_ids, max_length=100, num_beams=4)\n",
        "\n",
        "french_translation = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"English Input:\", english_text)\n",
        "print(\"French Translation:\", french_translation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij418raFF9ZS",
        "outputId": "90b96966-8488-4b69-9044-d704b7de3a09"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Input: Hello, how are you?\n",
            "French Translation: Hello, c'est-à-dire?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OX3Z7DMTGWAc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task 5: Programmatically print the names of all the model layers and their dimensions:\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT2V-aWVGYZg",
        "outputId": "eaa042bc-e63f-41f4-f403-1d5ab111a4bb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shared.weight torch.Size([32128, 512])\n",
            "encoder.block.0.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "encoder.block.0.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "encoder.block.0.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "encoder.block.0.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 6])\n",
            "encoder.block.0.layer.0.layer_norm.weight torch.Size([512])\n",
            "encoder.block.0.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "encoder.block.0.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "encoder.block.0.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "encoder.block.0.layer.1.layer_norm.weight torch.Size([512])\n",
            "encoder.block.1.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "encoder.block.1.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "encoder.block.1.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "encoder.block.1.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "encoder.block.1.layer.0.layer_norm.weight torch.Size([512])\n",
            "encoder.block.1.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "encoder.block.1.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "encoder.block.1.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "encoder.block.1.layer.1.layer_norm.weight torch.Size([512])\n",
            "encoder.block.2.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "encoder.block.2.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "encoder.block.2.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "encoder.block.2.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "encoder.block.2.layer.0.layer_norm.weight torch.Size([512])\n",
            "encoder.block.2.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "encoder.block.2.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "encoder.block.2.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "encoder.block.2.layer.1.layer_norm.weight torch.Size([512])\n",
            "encoder.block.3.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "encoder.block.3.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "encoder.block.3.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "encoder.block.3.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "encoder.block.3.layer.0.layer_norm.weight torch.Size([512])\n",
            "encoder.block.3.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "encoder.block.3.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "encoder.block.3.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "encoder.block.3.layer.1.layer_norm.weight torch.Size([512])\n",
            "encoder.block.4.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "encoder.block.4.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "encoder.block.4.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "encoder.block.4.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "encoder.block.4.layer.0.layer_norm.weight torch.Size([512])\n",
            "encoder.block.4.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "encoder.block.4.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "encoder.block.4.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "encoder.block.4.layer.1.layer_norm.weight torch.Size([512])\n",
            "encoder.block.5.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "encoder.block.5.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "encoder.block.5.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "encoder.block.5.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "encoder.block.5.layer.0.layer_norm.weight torch.Size([512])\n",
            "encoder.block.5.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "encoder.block.5.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "encoder.block.5.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "encoder.block.5.layer.1.layer_norm.weight torch.Size([512])\n",
            "encoder.block.6.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "encoder.block.6.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "encoder.block.6.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "encoder.block.6.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "encoder.block.6.layer.0.layer_norm.weight torch.Size([512])\n",
            "encoder.block.6.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "encoder.block.6.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "encoder.block.6.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "encoder.block.6.layer.1.layer_norm.weight torch.Size([512])\n",
            "encoder.block.7.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "encoder.block.7.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "encoder.block.7.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "encoder.block.7.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "encoder.block.7.layer.0.layer_norm.weight torch.Size([512])\n",
            "encoder.block.7.layer.1.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "encoder.block.7.layer.1.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "encoder.block.7.layer.1.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "encoder.block.7.layer.1.layer_norm.weight torch.Size([512])\n",
            "encoder.final_layer_norm.weight torch.Size([512])\n",
            "decoder.block.0.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.0.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.0.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.0.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 6])\n",
            "decoder.block.0.layer.0.layer_norm.weight torch.Size([512])\n",
            "decoder.block.0.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.0.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.0.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.0.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.0.layer.1.layer_norm.weight torch.Size([512])\n",
            "decoder.block.0.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "decoder.block.0.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "decoder.block.0.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "decoder.block.0.layer.2.layer_norm.weight torch.Size([512])\n",
            "decoder.block.1.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.1.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.1.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.1.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.1.layer.0.layer_norm.weight torch.Size([512])\n",
            "decoder.block.1.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.1.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.1.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.1.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.1.layer.1.layer_norm.weight torch.Size([512])\n",
            "decoder.block.1.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "decoder.block.1.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "decoder.block.1.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "decoder.block.1.layer.2.layer_norm.weight torch.Size([512])\n",
            "decoder.block.2.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.2.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.2.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.2.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.2.layer.0.layer_norm.weight torch.Size([512])\n",
            "decoder.block.2.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.2.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.2.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.2.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.2.layer.1.layer_norm.weight torch.Size([512])\n",
            "decoder.block.2.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "decoder.block.2.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "decoder.block.2.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "decoder.block.2.layer.2.layer_norm.weight torch.Size([512])\n",
            "decoder.block.3.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.3.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.3.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.3.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.3.layer.0.layer_norm.weight torch.Size([512])\n",
            "decoder.block.3.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.3.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.3.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.3.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.3.layer.1.layer_norm.weight torch.Size([512])\n",
            "decoder.block.3.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "decoder.block.3.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "decoder.block.3.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "decoder.block.3.layer.2.layer_norm.weight torch.Size([512])\n",
            "decoder.block.4.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.4.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.4.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.4.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.4.layer.0.layer_norm.weight torch.Size([512])\n",
            "decoder.block.4.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.4.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.4.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.4.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.4.layer.1.layer_norm.weight torch.Size([512])\n",
            "decoder.block.4.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "decoder.block.4.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "decoder.block.4.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "decoder.block.4.layer.2.layer_norm.weight torch.Size([512])\n",
            "decoder.block.5.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.5.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.5.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.5.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.5.layer.0.layer_norm.weight torch.Size([512])\n",
            "decoder.block.5.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.5.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.5.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.5.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.5.layer.1.layer_norm.weight torch.Size([512])\n",
            "decoder.block.5.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "decoder.block.5.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "decoder.block.5.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "decoder.block.5.layer.2.layer_norm.weight torch.Size([512])\n",
            "decoder.block.6.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.6.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.6.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.6.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.6.layer.0.layer_norm.weight torch.Size([512])\n",
            "decoder.block.6.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.6.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.6.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.6.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.6.layer.1.layer_norm.weight torch.Size([512])\n",
            "decoder.block.6.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "decoder.block.6.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "decoder.block.6.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "decoder.block.6.layer.2.layer_norm.weight torch.Size([512])\n",
            "decoder.block.7.layer.0.SelfAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.7.layer.0.SelfAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.7.layer.0.SelfAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.7.layer.0.SelfAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.7.layer.0.layer_norm.weight torch.Size([512])\n",
            "decoder.block.7.layer.1.EncDecAttention.q.weight torch.Size([384, 512])\n",
            "decoder.block.7.layer.1.EncDecAttention.k.weight torch.Size([384, 512])\n",
            "decoder.block.7.layer.1.EncDecAttention.v.weight torch.Size([384, 512])\n",
            "decoder.block.7.layer.1.EncDecAttention.o.weight torch.Size([512, 384])\n",
            "decoder.block.7.layer.1.layer_norm.weight torch.Size([512])\n",
            "decoder.block.7.layer.2.DenseReluDense.wi_0.weight torch.Size([1024, 512])\n",
            "decoder.block.7.layer.2.DenseReluDense.wi_1.weight torch.Size([1024, 512])\n",
            "decoder.block.7.layer.2.DenseReluDense.wo.weight torch.Size([512, 1024])\n",
            "decoder.block.7.layer.2.layer_norm.weight torch.Size([512])\n",
            "decoder.final_layer_norm.weight torch.Size([512])\n",
            "lm_head.weight torch.Size([32128, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UX4IbzZNGfk0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task 6: Programmatically print the total number of parameters/weights in this model:\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total parameters:\", total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNStFz2rGp1a",
        "outputId": "75cc63c7-03ff-4213-ed0d-cce2ee7139fa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 76961152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9JQ9FLhOGvIV"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task 7: Set the tensor in the final layer (decoder.final_layer_norm.weight) to all zeros:\n",
        "\n",
        "model.decoder.final_layer_norm.weight.data.fill_(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqZ9s9-IGxMt",
        "outputId": "00074772-0e13-4dc2-d45d-3d7d1838fbdd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pyKXyBBGG4ZB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task 8: Verify if the Q&A task works after resetting the weights of the above layer:\n",
        "\n",
        "context = \"Albert Einstein was a German-born theoretical physicist who developed the theory of relativity.\"\n",
        "question = \"Who was Albert Einstein?\"\n",
        "\n",
        "input_text = f\"question: {question} context: {context}\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "output = model.generate(input_ids)\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(\" \")\n",
        "print(\" DECODED OUTPUT: \", decoded_output) # NOT WORKING AFTER SETTING THE TENSORS IN THE FINAL LAYER TO ZERO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ1dVL5YG6AA",
        "outputId": "e7467279-6fe5-4e6d-ef0b-8ffdbf9d36ed"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " DECODED OUTPUT:  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8A5WCQ-HB9Z"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task 9: Replace the decoder.final_layer_norm.weight with a layer of smaller dimensions and adjust all the dependent layers to match the dimension\n",
        "\n",
        "# Load the original model\n",
        "original_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "original_config = original_model.config\n",
        "\n",
        "# Modify the configuration to reduce the dimension of the final layer\n",
        "new_dim = 256 # @param {type:\"number\"}\n",
        "original_config.d_model = new_dim\n",
        "\n",
        "num_layers = original_config.num_layers\n",
        "scale_factor = new_dim / original_config.d_model\n",
        "for i in range(num_layers):\n",
        "    layer = original_model.decoder.layers[i]\n",
        "    layer.self_attn.k_proj.weight.data *= scale_factor\n",
        "    layer.self_attn.v_proj.weight.data *= scale_factor\n",
        "    layer.self_attn.q_proj.weight.data *= scale_factor\n",
        "    layer.self_attn.out_proj.weight.data *= scale_factor\n",
        "    layer.fc1.weight.data *= scale_factor\n",
        "    layer.fc2.weight.data *= scale_factor\n",
        "\n",
        "# Replace the final layer normalization weight tensor with smaller dimensions\n",
        "new_weight = torch.zeros(new_dim)\n",
        "original_model.decoder.final_layer_norm.weight.data = new_weight\n",
        "\n",
        "# original_model.save_pretrained(\"modified_flan_t5_small\")\n"
      ],
      "metadata": {
        "id": "o8lkDbYVHD24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ttxilV57IFmE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task 10: Reload the original google/flan-t5-small model:\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBlMMKYZIpnl",
        "outputId": "cc7d7336-0885-4c9f-a9ad-8fe4e3ebceb0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Fl8VICqIw7t"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task 11: Train the model for Q&A task\n",
        "\n",
        "\n",
        "squad_dataset = load_dataset(\"squad\")\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n",
        "\n",
        "# task-specific prefix\n",
        "task_prefix = \"answer:\"\n",
        "\n",
        "def preprocess(example):\n",
        "    context = example[\"context\"]\n",
        "    question = example[\"question\"]\n",
        "    answer = example[\"answers\"][\"text\"][0]\n",
        "    input_text = f\"{task_prefix} {question} context: {context}\"\n",
        "    target_text = answer\n",
        "    return {\"input_text\": input_text, \"target_text\": target_text}\n",
        "\n",
        "train_dataset = squad_dataset[\"train\"].map(preprocess, remove_columns=[\"context\", \"question\", \"answers\"])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "lr = 5e-5 # @param {type:\"number\"}\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_epochs = 3 # @param {type:\"number\"}\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    for batch in progress_bar:\n",
        "        input_ids = tokenizer(batch[\"input_text\"], return_tensors=\"pt\", padding=True, truncation=True, max_length=512).input_ids.to(device)\n",
        "        labels = tokenizer(batch[\"target_text\"], return_tensors=\"pt\", padding=True, truncation=True, max_length=32).input_ids.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Update tqdm progress bar current loss\n",
        "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "model.save_pretrained(\"qa_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "3d9292aae5324a42a6390b22ddbd9671",
            "04f9043f5a73428fb8f9ab73156b54dd",
            "c9e162486e794259a42a75a4ceaf8c59",
            "055a8bf73e044a4b892013aa1544ae5e",
            "4b230d64e9ec485d8be30cac6ef8b3ff",
            "761d5d89812c4aaea92dc2a68f872c10",
            "4ca0a35edd3f434ca4ff2bcfb551daf2",
            "ab5c436670bc462e828fcbad19fb0769",
            "a23973a6eb6141c49626931c8ced16b5",
            "9d6805ed26074739bf9640c5d1886719",
            "2103c917c61a4283bb31fe48bf113008"
          ]
        },
        "id": "uUATn4_jJFaU",
        "outputId": "1b4e4719-9587-4f36-af98-4abb2e688475"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d9292aae5324a42a6390b22ddbd9671"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 10950/10950 [36:42<00:00,  4.97it/s, loss=0.287]\n",
            "Epoch 2/3: 100%|██████████| 10950/10950 [36:42<00:00,  4.97it/s, loss=0.139]\n",
            "Epoch 3/3: 100%|██████████| 10950/10950 [36:49<00:00,  4.96it/s, loss=0.21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9UEFTZToJ7DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Task 11: Evaluate the model"
      ],
      "metadata": {
        "id": "mLmojkGd5pio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squad_validation_dataset = load_dataset(\"squad\", split=\"validation\")\n",
        "\n",
        "trained_model = T5ForConditionalGeneration.from_pretrained(\"qa_model\")\n",
        "# tokenizer = T5Tokenizer.from_pretrained(\"qa_model\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "trained_model.to(device)"
      ],
      "metadata": {
        "id": "Is0Z1FrC5nar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# task-specific prefix\n",
        "task_prefix = \"question:\"\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "def generate_answer(context, question):\n",
        "\n",
        "    input_text = f\"{task_prefix} {question} context: {context}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
        "\n",
        "    output_ids = trained_model.generate(input_ids, max_length=32, num_beams=4, early_stopping=True)\n",
        "\n",
        "    answer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "for example in squad_validation_dataset:\n",
        "\n",
        "    context = example[\"context\"]\n",
        "    question = example[\"question\"]\n",
        "\n",
        "    prediction = generate_answer(context, question)\n",
        "    reference = example[\"answers\"][\"text\"][0]\n",
        "\n",
        "    predictions.append({\"prediction_text\": prediction, \"id\": example[\"id\"]})\n",
        "    references.append({\"answers\": {\"answer_start\": [0], \"text\": [reference]}, \"id\": example[\"id\"]})\n",
        "\n",
        "# Initialize SQuAD evaluation metric\n",
        "squad_metric = load_metric(\"squad\")\n",
        "\n",
        "results = squad_metric.compute(predictions=predictions, references=references)\n",
        "\n",
        "print(\"Evaluation Scores:\", results)\n"
      ],
      "metadata": {
        "id": "iTVjROvmKA7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e52018a-250c-4271-c712-8aa9243772bd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:753: FutureWarning: The repository for squad contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/squad/squad.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Scores: {'exact_match': 62.44087038789026, 'f1': 77.24002690297677}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EsTCN5EY3yda"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}